I"c<h1 id="introduction">Introduction</h1>

<p>Containerized Data Importer (CDI) is a utility to import, upload and clone Virtual Machine images for use with <a href="https://github.com/kubevirt/kubevirt">KubeVirt</a>. At a high level, a persistent volume claim (PVC), which defines VM-suitable storage via a storage class, is created.</p>

<p>A custom controller watches for specific annotation on the persistent volume claim, and when discovered, starts an import, upload or clone process. The status of the each process is reflected in an additional annotation on the associated claim, and when the process completes KubeVirt can create the VM based on the new image.</p>

<p>The Containerized Data Cloner gives the option to clone the imported/uploaded VM image from one PVC to another one either within the same namespace or across two different namespaces.</p>

<p>This Containerized Data Importer project is designed with KubeVirt in mind and provides a declarative method for importing amd uploading VM images into a Kuberenetes cluster. KubeVirt detects when the VM disk image import/upload is complete and uses the same PVC that triggered the import/upload process, to create the VM.</p>

<p>This approach supports two main use-cases:</p>

<ul>
  <li>A cluster administrator can build an abstract registry of immutable images (referred to as “Golden Images”) which can be cloned and later consumed by KubeVirt</li>
  <li>An ad-hoc user (granted access) can import a VM image into their own namespace and feed this image directly to KubeVirt, bypassing the cloning step</li>
</ul>

<p>For an in depth look at the system and workflow, see the <a href="https://github.com/kubevirt/containerized-data-importer/blob/master/doc/design.md#design">Design</a> documentation.</p>

<h1 id="data-format">Data Format</h1>

<p>The Containerized Data Importer is capable of performing certain functions that streamline its use with KubeVirt. It automatically decompresses gzip and xz files, and un-tar’s tar archives. Also, qcow2 images are converted into the raw format which is required by KubeVirt, resulting in the final file being a simple .img file.</p>

<p>Supported file formats are:</p>

<ul>
  <li>Tar archive</li>
  <li>Gzip compressed file</li>
  <li>XZ compressed file</li>
  <li>Raw image data</li>
  <li>ISO image data</li>
  <li>Qemu qcow2 image data</li>
</ul>

<p>Note: CDI also supports combinations of these formats such as gzipped tar archives, gzipped raw images, etc.</p>

<h1 id="deploying-cdi">Deploying CDI</h1>

<h2 id="assumptions">Assumptions</h2>

<ul>
  <li>A running Kubernetes cluster that is capable of binding PVCs to dynamically or statically provisioned PVs.</li>
  <li>A storage class and provisioner (only for dynamically provisioned PVs).</li>
  <li>An HTTP file server hosting VM images</li>
  <li>An optional “golden” namespace acting as the image repository. The default namespace is fine for tire kicking.</li>
</ul>

<h2 id="deploy-cdi-from-a-release">Deploy CDI from a release</h2>

<p>Deploying the CDI controller is straight forward. In this document the default namespace is used, but in a production setup a <a href="https://github.com/kubevirt/containerized-data-importer#protecting-the-golden-image-namespace">protected namespace</a> that is inaccessible to regular users should be used instead.</p>

<ol>
  <li>Ensure that the cdi-sa service account has proper authority to run privileged containers, typically in a kube environment this is true by default. If you are running an openshift variation of kubernetes you may need to enable privileged containers in the security context:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>oc adm policy add-scc-to-user privileged <span class="nt">-z</span> cdi-sa
</code></pre></div></div>

<ol>
  <li>Deploy the controller from the release manifest:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ VERSION</span><span class="o">=</span>&lt;cdi version&gt;
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl create <span class="nt">-f</span> https://github.com/kubevirt/containerized-data-importer/releases/download/<span class="nv">$VERSION</span>/cdi-controller.yaml
</code></pre></div></div>

<h2 id="deploy-cdi-using-a-template">Deploy CDI using a template</h2>

<p>By default when using manifests/generated/cdi-controller.yaml CDI will deploy into the kube-system namespace using default settings. You can customize the deployment by using the generated manifests/generated/cdi-controller.yaml.j2 jinja2 template. This allows you to alter the install namespace, docker image repo, docker image tags, etc. To deploy using the template follow these steps:</p>

<ol>
  <li>Install j2cli:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>pip <span class="nb">install </span>j2cli
</code></pre></div></div>

<ol>
  <li>Install CDI:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ cdi_namespace</span><span class="o">=</span>default <span class="se">\</span>
  <span class="nv">docker_prefix</span><span class="o">=</span>kubevirt <span class="se">\</span>
  <span class="nv">docker_tag</span><span class="o">=</span>v1.2.0 <span class="se">\</span>
  <span class="nv">pull_policy</span><span class="o">=</span>IfNotPresent <span class="se">\</span>
  <span class="nv">verbosity</span><span class="o">=</span>1 <span class="se">\</span>
  j2 manifests/generated/cdi-controller.yaml.j2 | kubectl create <span class="nt">-f</span> -
</code></pre></div></div>

<p>Check the template file and make sure to supply values for all variables.</p>

<p>Notes:</p>

<ul>
  <li>The default verbosity level is set to 1 in the controller deployment file, which is minimal logging. If greater details are desired increase the -v number to 2 or 3.</li>
  <li>The importer pod uses the same logging verbosity as the controller. If a different level of logging is required after the controller has been started, the deployment can be edited and applied by using kubectl apply -f <CDI-MANIFEST>. This will not alter the running controller's logging level but will affect importer pods created after the change. To change the running controller's log level requires it to be restarted after the deployment has been edited.</CDI-MANIFEST></li>
</ul>

<h1 id="download-cdi">Download CDI</h1>

<p>There are few ways to download CDI through command line:</p>

<ul>
  <li>git clone command:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/kubevirt/containerized-data-importer.git <span class="nv">$GOPATH</span>/src/kubevirt.io/containerized-data-importer
</code></pre></div></div>

<ul>
  <li>download only the yamls:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>cdi-manifests <span class="o">&amp;&amp;</span> <span class="nb">cd </span>cdi-manifests
<span class="nv">$ </span>wget https://raw.githubusercontent.com/kubevirt/containerized-data-importer/kubevirt-centric-readme/manifests/example/golden-pvc.yaml
<span class="nv">$ </span>wget https://raw.githubusercontent.com/kubevirt/containerized-data-importer/kubevirt-centric-readme/manifests/example/endpoint-secret.yaml
</code></pre></div></div>

<ul>
  <li>go get command:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>go get kubevirt.io/containerized-data-importer
</code></pre></div></div>

<h1 id="start-importing-images">Start Importing Images</h1>

<p>Import disk image is achieved by creating a new PVC with the ‘cdi.kubevirt.io/storage.import.endpoint’ annotation indicating the url of the source image that we want to download from. Once the controller detects the PVC, it starts a pod which is responsible for importing the image from the given url.</p>

<h2 id="create-a-pvc-yaml-file-named-golden-pvcyaml">Create a PVC yaml file named golden-pvc.yaml</h2>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">golden-pvc"</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">containerized-data-importer</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="s">cdi.kubevirt.io/storage.import.endpoint</span><span class="pi">:</span> <span class="s2">"</span><span class="s">https://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img"</span> <span class="c1"># Required. Format: (http||s3)://www.myUrl.com/path/of/data</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">10Gi</span>
  <span class="c1"># Optional: Set the storage class or omit to accept the default</span>
  <span class="c1"># storageClassName: local</span>
</code></pre></div></div>

<p>Edit the PVC above -</p>

<ul>
  <li>cdi.kubevirt.io/storage.import.endpoint: The full URL to the VM image in the format of: http://www.myUrl.com/path/of/data or s3://bucketName/fileName.</li>
  <li>storageClassName: The default StorageClass will be used if not set. Otherwise, set to a desired StorageClass.</li>
</ul>

<p>Note: It is possible to use authentication when importing the image from the endpoint url. Please see <a href="https://github.com/kubevirt/containerized-data-importer/blob/master/manifests/example/endpoint-secret.yaml">using secret during import</a></p>

<h2 id="deploy-the-manifest-yaml-files">Deploy the manifest yaml files</h2>

<ol>
  <li>Create the persistent volume claim to trigger the import process:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;NAMESPACE&gt; create <span class="nt">-f</span> golden-pvc.yaml
</code></pre></div></div>

<ol>
  <li>(Optional) Monitor the cdi-controller:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;CDI-NAMESPACE&gt; logs cdi-deployment-&lt;RANDOM&gt;
</code></pre></div></div>

<ol>
  <li>(Optional )Monitor the importer pod:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;NAMESPACE&gt; logs importer-&lt;PVC-NAME&gt; <span class="c"># pvc name is shown in controller log</span>
</code></pre></div></div>

<ol>
  <li>Verify the import is completed by checking the following annotation value:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;NAMESPACE&gt; get pvc golden-pvc.yaml <span class="nt">-o</span> yaml
</code></pre></div></div>

<p>annotation to verify - cdi.kubevirt.io/storage.pod.phase: Succeeded</p>

<h1 id="start-cloning-disk-image">Start cloning disk image</h1>

<p>Cloning is achieved by creating a new PVC with the ‘k8s.io/CloneRequest’ annotation indicating the name of the PVC the image is copied from. Once the controller detects the PVC, it starts two pods (source and target pods) which are responsible for the cloning of the image from one PVC to another using a unix socket that is created on the host itself.</p>

<p>When the cloning is completed, the PVC which the image was copied to, is assigned with the ‘k8s.io/CloneOf’ annotation to indicate cloning completion. The copied VM image can be used by a new pod only after the cloning process is completed.</p>

<p>The two cloning pods must execute on the same node. Pod adffinity is used to enforce this requirement; however, the cluster also needs to be configured to delay volume binding until pod scheduling has completed.</p>

<p>When using local storage and Kubernetes 1.9 and older, export KUBE_FEATURE_GATES before bringing up the cluster:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">export </span><span class="nv">KUBE_FEATURE_GATES</span><span class="o">=</span><span class="s2">"PersistentLocalVolumes=true,VolumeScheduling=true,MountPropagation=true"</span>
</code></pre></div></div>

<p>These features default to true in Kubernetes 1.10 and later and thus do not need to be set.
Regardless of the Kubernetes version, a storage class with volumeBindingMode set to “WaitForFirstConsumer” needs to be created. Eg:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
   <span class="s">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
   <span class="s">metadata</span><span class="pi">:</span>
     <span class="na">name</span><span class="pi">:</span> <span class="s">&lt;local-storage-name&gt;</span>
   <span class="na">provisioner</span><span class="pi">:</span> <span class="s">kubernetes.io/no-provisioner</span>
   <span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">WaitForFirstConsumer</span>
</code></pre></div></div>

<h2 id="create-a-pvc-yaml-file-named-target-pvcyaml">Create a PVC yaml file named target-pvc.yaml</h2>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">target-pvc"</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s2">"</span><span class="s">target-ns"</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">Host-Assisted-Cloning</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="s">k8s.io/CloneRequest</span><span class="pi">:</span> <span class="s2">"</span><span class="s">source-ns/golden-pvc"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">10Gi</span>
</code></pre></div></div>

<p>Edit the PVC above -</p>

<ul>
  <li>k8s.io/CloneRequest: The name of the PVC we copy the image from (including its namespace). For example: “source-ns/golden-pvc”.</li>
  <li>add the name of the storage class which defines volumeBindingMode per above. Note, this is not required in Kubernetes 1.10 and later.</li>
</ul>

<h2 id="deploy-the-manifest-yaml-files-1">Deploy the manifest yaml files</h2>

<ol>
  <li>(Optional) Create the namespace where the target PVC will be deployed:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl create ns &lt;TARGET-NAMESPACE&gt;
</code></pre></div></div>

<ol>
  <li>Deploy the target PVC:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;TARGET-NAMESPACE&gt; create <span class="nt">-f</span> target-pvc.yaml
</code></pre></div></div>

<ol>
  <li>(Optional) Monitor the cloning pods:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;SOURCE-NAMESPACE&gt; logs &lt;clone-source-pod-name&gt;
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;TARGET-NAMESPACE&gt; logs &lt;clone-target-pod-name&gt;
</code></pre></div></div>

<ol>
  <li>Check the target PVC for ‘k8s.io/CloneOf’ annotation:</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nt">-n</span> &lt;TARGET-NAMESPACE&gt; get pvc &lt;target-pvc-name&gt; <span class="nt">-o</span> yaml
</code></pre></div></div>

<h1 id="start-uploading-disk-image">Start uploading disk image</h1>

<p>Uploading a disk image is achieved by creating a new PVC with the ‘cdi.kubevirt.io/storage.upload.target’ annotation indicating the request for uploading. Part of the uploading process is the authentication of upload requests with an UPLOAD_TOKEN header. The user posts an upload token request to the cluster, and the encrypted Token is returned immediately within the response in the status field. For this to work, a dedicated service is deployed with a nodePort field. At that point, a curl request including the token is sent to start the upload process. Given the upload PVC and the curl request, the controller starts a pod which is responsible for uploading the local image to the PVC.</p>

<h2 id="create-a-pvc-yaml-file-named-upload-pvcyaml">Create a PVC yaml file named upload-pvc.yaml</h2>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">upload-pvc</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">containerized-data-importer</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="s">cdi.kubevirt.io/storage.upload.target</span><span class="pi">:</span> <span class="s2">"</span><span class="s">"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">1Gi</span>
</code></pre></div></div>

<h2 id="create-the-upload-tokenyaml-file">Create the upload-token.yaml file</h2>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">upload.cdi.kubevirt.io/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">UploadTokenRequest</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">upload-pvc</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">default</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">pvcName</span><span class="pi">:</span> <span class="s">upload-pvc</span>
</code></pre></div></div>

<h2 id="upload-an-image">Upload an image</h2>

<ol>
  <li>deploy the upload-pvc</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> upload-pvc.yaml
</code></pre></div></div>

<ol>
  <li>Request for upload token</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ TOKEN</span><span class="o">=</span><span class="si">$(</span>kubectl apply <span class="nt">-f</span> upload-token.yaml <span class="nt">-o</span><span class="o">=</span><span class="s2">"jsonpath={.status.token}"</span><span class="si">)</span>
</code></pre></div></div>

<ol>
  <li>Upload the image</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">--insecure</span> <span class="nt">-H</span> <span class="s2">"Authorization: Bearer </span><span class="nv">$TOKEN</span><span class="s2">"</span> <span class="nt">--data-binary</span> @tests/images/cirros-qcow2.img https://<span class="si">$(</span>minikube ip<span class="si">)</span>:31001/v1alpha1/upload
</code></pre></div></div>

<h1 id="security-configurations">Security Configurations</h1>

<h2 id="rbac-roles">RBAC Roles</h2>

<p>CDI runs under a custom ServiceAccount (cdi-sa) and uses the <a href="https://v1-13.docs.kubernetes.io/docs/reference/access-authn-authz/rbac/">Kubernetes RBAC model</a> to apply an application specific custom ClusterRole with rules to properly access needed resources such as PersistentVolumeClaims and Pods.</p>

<h2 id="protecting-vm-image-namespaces">Protecting VM Image Namespaces</h2>

<p>Currently there is no support for automatically implementing <a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">Kubernetes ResourceQuotas</a> and Limits on desired namespaces and resources, therefore administrators need to manually lock down all new namespaces from being able to use the StorageClass associated with CDI/KubeVirt and cloning capabilities. This capability of automatically restricting resources is planned for future releases. Below are some examples of how one might achieve this level of resource protection:</p>

<ul>
  <li>Lock Down StorageClass Usage for Namespace:</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ResourceQuota</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">protect-mynamespace</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hard</span><span class="pi">:</span>
    <span class="s">&lt;STORAGE-CLASS-NAME&gt;.storageclass.storage.k8s.io/requests.storage</span><span class="pi">:</span> <span class="s2">"</span><span class="s">0"</span>
</code></pre></div></div>

<div class="premonition note"><div class="fa fa-check-square"></div><div class="content"><p class="header">Note</p><p><code class="highlighter-rouge">.storageclass.storage.k8s.io/persistentvolumeclaims: "0"</code> would also accomplish the same affect by not allowing any pvc requests against the storageclass for this namespace.</p>


</div></div>
<ul>
  <li>Open Up StorageClass Usage for Namespace:</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ResourceQuota</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">protect-mynamespace</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hard</span><span class="pi">:</span>
    <span class="s">&lt;STORAGE-CLASS-NAME&gt;.storageclass.storage.k8s.io/requests.storage</span><span class="pi">:</span> <span class="s2">"</span><span class="s">500Gi"</span>
</code></pre></div></div>

<div class="premonition note"><div class="fa fa-check-square"></div><div class="content"><p class="header">Note</p><p><code class="highlighter-rouge">.storageclass.storage.k8s.io/persistentvolumeclaims: "4"</code> could be used and this would only allow for 4 pvc requests in this namespace, anything over that would be denied.</p>


</div></div>
:ET